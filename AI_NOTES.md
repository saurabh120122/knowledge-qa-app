
# ğŸ¤– AI Usage Documentation

This section explains how AI tools were used during development, what was independently verified, and the reasoning behind key technical decisions.

---

## ğŸ“Š AI Usage Breakdown

### ğŸ”¹ What AI Was Used For

#### 1. Boilerplate Code Generation (~40%)
- FastAPI route structures (standard CRUD patterns)
- React component templates
- Configuration files:
  - requirements.txt
  - package.json
  - vercel.json
  - render.yaml
- CORS middleware setup
- Pydantic request/response schemas

Why: These are standardized patterns where manual typing adds little value.

---

#### 2. Initial RAG Implementation (~30%)
- ChromaDB initialization & configuration
- Embedding API call structure (Gemini)
- Text chunking using RecursiveCharacterTextSplitter
- Similarity search query patterns

Why: Used AI for standard RAG scaffolding, then customized for project needs.

---

#### 3. Deployment Configuration (~10%)
- Render service template
- Vercel SPA routing
- .env.example structure

Why: Platform configs change frequently â†’ templates save time.

---

#### 4. Error Interpretation
- Dependency conflicts
- CORS issues
- ChromaDB telemetry warnings
- Render deployment logs

Why: Faster diagnosis of common framework issues.

---

#### 5. Documentation Formatting
- Markdown structuring
- API documentation layout
- Technical write-up templates

---

## ğŸ§  Independent Engineering Decisions & Understanding

### âœ… RAG Architecture Design

Core Understanding:
- Embeddings convert text â†’ high-dimensional semantic vectors
- Cosine similarity measures semantic closeness
- LLM is used only for generation â€” not retrieval
- Embeddings are created once at upload, not per query

Why It Matters:
This design makes queries fast and scalable.

---

### âœ… Error Handling Strategy

Transactional Upload:

```python
try:
    save_file()
    extract_text()
    chunk_text()
    generate_embeddings()
    store_in_chromadb()
except Exception:
    if os.path.exists(file_path):
        os.remove(file_path)
    raise
```

Result:
- No orphaned files
- Clean retry flow
- Consistent system state

---

### âœ… LLM Provider Selection

Final Choice â†’ Google Gemini

Why:
- Generous free tier
- Comparable quality
- Fast responses
- Simple integration

Models Used:
- Embeddings â†’ gemini-embedding-001
- Generation â†’ gemini-3-flash-preview

---

### âœ… Deployment Platform Decision

Railway Issue: Port mapping failure despite correct config  
Switch â†’ Render

Why:
- Clear FastAPI deployment flow
- Fewer moving parts
- Faster production readiness

---

### âœ… Python Version Resolution (Render)

Fix:
PYTHON_VERSION=3.11.9

---

### âœ… Storage Strategy

Render Free Tier Limitation: No persistent disk

Decision for Demo:
- Use temporary storage
- Document limitation clearly

Production Approach:
- S3 / GCS â†’ document storage
- Managed vector DB â†’ Pinecone / Weaviate

---

## ğŸ§ª Testing Methodology

Functional Testing:
- 10+ documents uploaded
- 50+ query variations
- Manual source verification

Edge Cases:
- Unsupported formats
- Empty files
- Invalid API keys

Performance:
- Upload time measurement
- Concurrent uploads
- Vector query latency

---

## ğŸ¯ Development Philosophy

AI = Accelerator, Not Decision Maker

Used AI For:
- Speed
- Best practices
- Boilerplate
- Debug hints

Not Used AI For:
- Architecture
- Trade-offs
- Core logic
- System design

Rule:
Never merge code without understanding it.

---

## ğŸ Final Outcome

âœ” Fully functional RAG system  
âœ” Clean architecture  
âœ” Production deployment  
âœ” Transparent limitations  
âœ” Complete technical ownership  

AI accelerated development â€” engineering decisions remained human.
